# train_model.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import pickle
import os
import xgboost as xgb
import shap

print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")

# –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
file_path = "data/synthetic_coffee_health_10000.csv"

if not os.path.exists(file_path):
    print(f"‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
    print("1. –§–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ 'data'")
    print("2. –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Ç–æ—á–Ω–æ: 'synthetic_coffee_health_10000.csv'")
    exit()
else:
    print("‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω!")

# –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
try:
    df = pd.read_csv(file_path)
    print("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
    exit()

# –®–∞–≥ 3: –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
print("\nüìä –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö:")
print(df.head())

print("\nüîç –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
print(df.info())

print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
print(df.describe())

print("\nüéØ –°—Ç–æ–ª–±—Ü—ã –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
for i, col in enumerate(df.columns, 1):
    print(f"{i}. {col}")

print("\nüî¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:")
print(df.isnull().sum())

print("\nüéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏...")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∏–ø–æ–≤ —Å–Ω–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π)
def create_sleep_type(row):
    """
    –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏.
    """
    score = 0

    # –ö–∞—á–µ—Å—Ç–≤–æ –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–Ω–∞
    if row['Sleep_Quality'] == 'Excellent':
        score += 3
    elif row['Sleep_Quality'] == 'Good':
        score += 1
    elif row['Sleep_Quality'] == 'Fair':
        score -= 1
    elif row['Sleep_Quality'] == 'Poor':
        score -= 3
    
    if row['Sleep_Hours'] > 7.5:
        score += 2
    elif row['Sleep_Hours'] < 6:
        score -= 2

    # –£—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞
    if row['Stress_Level'] == 'Low':
        score += 1
    elif row['Stress_Level'] == 'Medium':
        score -= 1
    elif row['Stress_Level'] == 'High':
        score -= 3

    # –§–∏–∑–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    if row['Physical_Activity_Hours'] > 5:
        score += 1
    elif row['Physical_Activity_Hours'] < 1:
        score -= 1
        
    # –í—Ä–µ–¥–Ω—ã–µ –ø—Ä–∏–≤—ã—á–∫–∏
    if row['Alcohol_Consumption'] > 0:
        score -= 2
    if row['Smoking'] > 0:
        score -= 2

    # –ö–æ—Ñ–µ–∏–Ω
    if row['Caffeine_mg'] > 300:
        score -= 2
        
    # –í–æ–∑—Ä–∞—Å—Ç
    if row['Age'] > 60:
        score -= 1
        
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º
    if row['Phone_Usage_Hours_Before_Sleep'] < 1:
        score -= 3
    elif row['Phone_Usage_Hours_Before_Sleep'] < 2:
        score -= 1

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –±–∞–ª–ª–∞–º
    if score >= 4:
        return '–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ–ª—å–Ω—ã–π'
    elif score >= 2:
        return '–°–ø–æ–∫–æ–π–Ω—ã–π'
    elif score >= 0:
        return '–ù–æ—Ä–º–∞–ª—å–Ω—ã–π'
    elif score >= -2:
        return '–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π'
    elif score >= -4:
        return '–ü—Ä–µ—Ä—ã–≤–∏—Å—Ç—ã–π'
    else:
        return '–ë–µ—Å–ø–æ–∫–æ–π–Ω—ã–π'


# –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º
def simulate_phone_usage(row):
    stress = row['Stress_Level']
    quality = row['Sleep_Quality']
    
    if stress == 'High' or quality == 'Poor':
        # –í—ã—Å–æ–∫–∏–π —Å—Ç—Ä–µ—Å—Å / –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–Ω–∞ -> –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –±–ª–∏–∂–µ –∫–æ —Å–Ω—É
        return round(np.random.uniform(0, 1.5), 1)
    elif stress == 'Medium' or quality == 'Fair':
        return round(np.random.uniform(0.5, 3.0), 1)
    else: # –ù–∏–∑–∫–∏–π —Å—Ç—Ä–µ—Å—Å / —Ö–æ—Ä–æ—à–µ–µ –∏–ª–∏ –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        return round(np.random.uniform(1.0, 4.0), 1)

df['Phone_Usage_Hours_Before_Sleep'] = df.apply(simulate_phone_usage, axis=1)

# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
df['sleep_type'] = df.apply(create_sleep_type, axis=1)

print("‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è 'sleep_type' —Å–æ–∑–¥–∞–Ω–∞!")
print("‚úÖ –°–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞!")
print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å–Ω–∞:")
print(df['sleep_type'].value_counts())

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
plt.figure(figsize=(10, 6))
df['sleep_type'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å–Ω–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ')
plt.xlabel('–¢–∏–ø —Å–Ω–∞')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('sleep_type_distribution.png')
# plt.show() # Removed to prevent blocking

print("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'sleep_type_distribution.png'")

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ train_model.py

print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏...")

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
selected_features = ['Age', 'Gender', 'Caffeine_mg', 
                    'Sleep_Hours', 'Sleep_Quality', 'Stress_Level', 'Physical_Activity_Hours',
                    'Smoking', 'Alcohol_Consumption', 'Phone_Usage_Hours_Before_Sleep']

# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π DataFrame —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
features_df = df[selected_features].copy()

# –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
from sklearn.preprocessing import LabelEncoder

# –ö–æ–¥–∏—Ä—É–µ–º –ø–æ–ª (–µ—Å–ª–∏ –µ—Å—Ç—å 'Other', –µ–≥–æ —Ç–æ–∂–µ –∫–æ–¥–∏—Ä—É–µ–º)
gender_encoder = LabelEncoder()
features_df['Gender_encoded'] = gender_encoder.fit_transform(features_df['Gender'])

# –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–Ω–∞
quality_encoder = LabelEncoder()
features_df['Sleep_Quality_encoded'] = quality_encoder.fit_transform(features_df['Sleep_Quality'])

# –ö–æ–¥–∏—Ä—É–µ–º —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞
stress_encoder = LabelEncoder()
features_df['Stress_Level_encoded'] = stress_encoder.fit_transform(features_df['Stress_Level'])

# –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
features_df = features_df.drop(['Gender', 'Sleep_Quality', 'Stress_Level'], axis=1)

print("‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")
print("\nüìã –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏:")
print(features_df.columns.tolist())

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
X = features_df
y = df['sleep_type']

target_encoder = LabelEncoder()
y_encoded = target_encoder.fit_transform(y)

print(f"\nüìä –†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ (X): {X.shape}")
print(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (y_encoded): {y_encoded.shape}")

# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

print(f"\nüìö –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")

# –®–∞–≥ 7: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
print("\nü§ñ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å XGBoost...")

model = xgb.XGBClassifier(
    objective='multi:softmax', # For multiclass classification, outputs class labels
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    use_label_encoder=False, # Suppress deprecation warning
    eval_metric='mlogloss', # Metric for multiclass logloss
    random_state=42
)

model.fit(X_train, y_train_encoded)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
y_pred_encoded = model.predict(X_test)

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
accuracy = accuracy_score(y_test_encoded, y_pred_encoded)
print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy:.2f}")

print("\nüìä –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
print(classification_report(y_test_encoded, y_pred_encoded, target_names=target_encoder.classes_))

# –®–∞–≥ 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å...")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
with open('sleep_type_model.pkl', 'wb') as f:
    pickle.dump(model, f)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –ø–æ–ª–∞
with open('gender_encoder.pkl', 'wb') as f:
    pickle.dump(gender_encoder, f)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
with open('target_encoder.pkl', 'wb') as f:
    pickle.dump(target_encoder, f)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞
with open('quality_encoder.pkl', 'wb') as f:
    pickle.dump(quality_encoder, f)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞
with open('stress_encoder.pkl', 'wb') as f:
    pickle.dump(stress_encoder, f)

print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'sleep_type_model.pkl'")
print("‚úÖ –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –ø–æ–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'gender_encoder.pkl'")
print("‚úÖ –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'target_encoder.pkl'")
print("‚úÖ –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'quality_encoder.pkl'")
print("‚úÖ –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'stress_encoder.pkl'")

# –®–∞–≥ 9: –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é SHAP
print("\nüìà –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é SHAP...")

# –°–æ–∑–¥–∞–µ–º –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å SHAP
explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
plt.title('–ì–ª–æ–±–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (SHAP)')
plt.tight_layout()
plt.savefig('shap_summary.png')
# plt.show() # –£–±–∏—Ä–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

print("‚úÖ –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SHAP —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'shap_summary.png'")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å SHAP
with open('shap_explainer.pkl', 'wb') as f:
    pickle.dump(explainer, f)
    
print("‚úÖ –û–±—ä—è—Å–Ω–∏—Ç–µ–ª—å SHAP —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'shap_explainer.pkl'")


print("üéâ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
print("\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
print("1. sleep_type_model.pkl - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
print("2. gender_encoder.pkl, quality_encoder.pkl, stress_encoder.pkl - –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∏")
print("3. target_encoder.pkl - –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
print("4. shap_explainer.pkl - –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å SHAP")
print("5. sleep_type_distribution.png - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å–Ω–∞")
print("6. shap_summary.png - –≥—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SHAP")